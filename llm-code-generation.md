## Paper collection for LLM code generation

## Introduction

## Papers

1. **DreamCoder: Bootstrapping Inductive Program Synthesis with Wake-Sleep Library Learning** PLDI 2021

    *Kevin Ellis, Catherine Wong, Maxwell Nye, Mathias Sablé-Meyer, Lucas Morales, Luke Hewitt, Luc Cary, Armando Solar-Lezama, oshua B. Tenenbaum*  [[pdf](https://dl.acm.org/doi/pdf/10.1145/3453483.3454080)]

1. **On-the-Fly Adaptation of Source Code Models using Meta-Learning** NeurIPS 2020 CAP Workshop

    *Disha Shrivastava, Hugo Larochelle, Daniel Tarlow*  [[pdf](https://arxiv.org/abs/2003.11768v1)], 2020.5.26

1. **Competition-Level Code Generation with AlphaCode.** Science 2022
   
    *Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d'Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, Oriol Vinyals*  [[pdf](https://arxiv.org/abs/2203.07814)], 2022.2.8

1. **An Exploratory Study on Code Attention in BERT.** ICPC 2022

   *Rishab Sharma, Fuxiang Chen, Fatemeh Fard, David Lo*  [[pdf](https://arxiv.org/abs/2204.10200)], 2022.4.5

1. **CoCoSoDa: Effective Contrastive Learning for Code Search.** ICSE 2023

   *Ensheng Shi, Yanlin Wang, Wenchao Gu, Lun Du, Hongyu Zhang, Shi Han, Dongmei Zhang, Hongbin Sun* [[pdf](https://arxiv.org/abs/2204.03293)], 2022.4.7

1. **Fault-Aware Neural Code Rankers.** NeurIPS 2022

   *Jeevana Priya Inala, Chenglong Wang, Mei Yang, Andres Codas, Mark Encarnación, Shuvendu K Lahiri, Madanlal Musuvathi, Jianfeng Gao*  [[pdf](https://arxiv.org/abs/2206.03865)], 2022.6.4

1. **Making Large Language Models Better Reasoners with Step-Aware Verifier.** ACL 2023

   *Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, Weizhu Chen*  [[pdf](https://arxiv.org/abs/2206.02336)], 2022.6.6

1. **CodeS: Towards Code Model Generalization Under Distribution Shift.** ICSE-NIER 2023

   *Qiang Hu, Yuejun Guo, Xiaofei Xie, Maxime Cordy, Lei Ma, Mike Papadakis, Yves Le Traon*  [[pdf](https://arxiv.org/abs/2206.05480)], 2022.6.11

1. **NatGen: Generative pre-training by "Naturalizing" source code.** ESEC/FSE 2022

   *Saikat Chakraborty, Toufique Ahmed, Yangruibo Ding, Premkumar Devanbu, Baishakhi Ray* [[pdf](https://arxiv.org/abs/2206.07585)], 2022.6.15

1. **Repository-Level Prompt Generation for Large Language Models of Code.** ICML 2023

    *Disha Shrivastava, Hugo Larochelle, Daniel Tarlow*  [[pdf](https://arxiv.org/abs/2206.12839)], 2022.6.26

1. **DocPrompting: Generating Code by Retrieving the Docs.** ICLR 2023

     *Shuyan Zhou, Uri Alon, Frank F. Xu, Zhiruo Wang, Zhengbao Jiang, Graham Neubig*  [[pdf](https://arxiv.org/abs/2207.05987)], 2022.7.13

1. **CodeT: Code Generation with Generated Tests.** ICLR 2023

     *Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, Weizhu Chen*  [[pdf](https://arxiv.org/abs/2207.10397)], 2022.7.21

1. **Neurosymbolic Repair for Low-Code Formula Languages.** OOPSLA 2022

     *Rohan Bavishi, Harshit Joshi, José Pablo Cambronero Sánchez, Anna Fariha, Sumit Gulwani, Vu Le, Ivan Radicek, Ashish Tiwari*  [[pdf](https://arxiv.org/abs/2207.11765)], 2022.7.24

1. **Language Models Can Teach Themselves to Program Better.** ICLR 2023

     *Patrick Haluptzok, Matthew Bowers, Adam Tauman Kalai*  [[pdf](https://arxiv.org/abs/2207.14502)], 2022.7.29

1. **CSSAM: Code Search via Attention Matching of Code Semantics and Structures.** SANER 2023

     *Yi Hu, Bo Cai, Yaoxiang Yu*  [[pdf](https://arxiv.org/abs/2208.03922)], 2022.8.8

1. **Incorporating Domain Knowledge through Task Augmentation for Front-End JavaScript Code Generation.** ESEC/FSE 2022

     *Sijie Shen, Xiang Zhu, Yihong Dong, Qizhi Guo, Yankun Zhen, Ge Li*  [[pdf](https://arxiv.org/abs/2208.10091)], 2022.8.22

1. **Code4Struct: Code Generation for Few-Shot Event Structure Prediction.** ACL 2023

     *Xingyao Wang, Sha Li, Heng Ji*  [[pdf](https://arxiv.org/abs/2210.12810)], 2022.10.23

1. **DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation.** ICML 2023

     *Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi Zhong, Luke Zettlemoyer, Scott Wen-tau Yih, Daniel Fried, Sida Wang, Tao Yu*  [[pdf](https://arxiv.org/abs/2211.11501)], 2022.11.18

1. **Coder Reviewer Reranking for Code Generation.** ICML 2023

     *Tianyi Zhang, Tao Yu, Tatsunori B. Hashimoto, Mike Lewis, Wen-tau Yih, Daniel Fried, Sida I. Wang*  [[pdf](https://arxiv.org/abs/2211.16490)], 2022.11.29

1. **Natural Language to Code Generation in Interactive Data Science Notebooks.** ACL 2023

    *Pengcheng Yin, Wen-Ding Li, Kefan Xiao, Abhishek Rao, Yeming Wen, Kensen Shi, Joshua Howland, Paige Bailey, Michele Catasta, Henryk Michalewski, Alex Polozov, Charles Sutton* [[pdf](https://arxiv.org/abs/2212.09248)], 2022.12.19
   
1. **Python Code Generation by Asking Clarification Questions.** ACL 2023

     *Haau-Sing Li, Mohsen Mesgar, André F. T. Martins, Iryna Gurevych*  [[pdf](https://arxiv.org/abs/2212.09885)], 2022.12.19

1. **Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments.** ACL 2023

    *Yu Gu, Xiang Deng, Yu Su*  [[pdf](https://arxiv.org/abs/2212.09736)], 2022.12.19

1. **Execution-Based Evaluation for Open-Domain Code Generation**

   *Zhiruo Wang, Shuyan Zhou, Daniel Fried, Graham Neubig*  [[pdf](https://arxiv.org/abs/2212.10481)], 2023.12.20

1. **Large language models are versatile decomposers: Decompose evidence and questions for table-based reasoning.** SIGIR 2023

    *Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, Yongbin Li*  [[pdf](https://arxiv.org/abs/2301.13808)], 2023.1.31

1. **Learning Performance-Improving Code Edits** Arxiv

   *Alexander Shypula, Aman Madaan, Yimeng Zeng, Uri Alon, Jacob Gardner, Milad Hashemi, Graham Neubig, Parthasarathy Ranganathan, Osbert Bastani, Amir Yazdanbakhsh* [[pdf](https://arxiv.org/abs/2302.07867)], 2023.2.15

1. **LEVER: Learning to Verify Language-to-Code Generation with Execution.** ICML 2023

     *Ansong Ni, Srini Iyer, Dragomir Radev, Ves Stoyanov, Wen-tau Yih, Sida I. Wang, Xi Victoria Lin*  [[pdf](https://arxiv.org/abs/2302.08468)], 2023.2.16
   
1. **EvoPrompting: Language Models for Code-Level Neural Architecture Search.** Arxiv

     *Angelica Chen, David M. Dohan, David R. So*  [[pdf](https://arxiv.org/abs/2302.14838)], 2023.2.28
   
1. **Planning with Large Language Models for Code Generation.** ICLR 2023

     *Shun Zhang, Zhenfang Chen, Yikang Shen, Mingyu Ding, Joshua B. Tenenbaum, Chuang Gan.*  [[pdf](https://arxiv.org/abs/2303.05510)], 2023.3.9
   
1. **Self-planning Code Generation with Large Language Model.** Arxiv

     *Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, Ge Li*  [[pdf](https://arxiv.org/abs/2303.06689)], 2023.3.12
   
1. **Reflexion: Language Agents with Verbal Reinforcement Learning.** Arxiv

     *Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao*  [[pdf](https://arxiv.org/abs/2303.11366)], 2023.3.20

1. **Teaching Large Language Models to Self-Debug.** Arxiv

     *Xinyun Chen, Maxwell Lin, Nathanael Schärli, Denny Zhou*  [[pdf](https://arxiv.org/abs/2304.05128)], 2023.4.11

1. **WizardLM: Empowering Large Language Models to Follow Complex Instructions.** Arxiv

     *Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Daxin Jiang*  [[pdf](https://arxiv.org/abs/2304.12244)], 2023.4.24

1. **Outline, Then Details: Syntactically Guided Coarse-To-Fine Code Generation.** ICML 2023

    *Wenqing Zheng, S P Sharan, Ajay Kumar Jaiswal, Kevin Wang, Yihan Xi, Dejia Xu, Zhangyang Wang*  [[pdf](https://arxiv.org/abs/2305.00909)], 2023.4.28

1. **From Words to Code: Harnessing Data for Program Synthesis from Natural Language.** Arxiv

     *Anirudh Khatry, Joyce Cahoon, Jordan Henkel, Shaleen Deep, Venkatesh Emani, Avrilia Floratou, Sumit Gulwani, Vu Le, Mohammad Raza, Sherry Shi, Mukul Singh, Ashish Tiwari*  [[pdf](https://arxiv.org/abs/2305.01598)], 2023.5.2

1. **Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs.** Arxiv

    *Jinyang Li, Binyuan Hui, Ge Qu, Binhua Li, Jiaxi Yang, Bowen Li, Bailin Wang, Bowen Qin, Rongyu Cao, Ruiying Geng, Nan Huo, Xuanhe Zhou, Chenhao Ma, Guoliang Li, Kevin C.C. Chang, Fei Huang, Reynold Cheng, Yongbin Li*  [[pdf](https://arxiv.org/abs/2305.03111)], 2023.5

1. **Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation.** Arxiv

     *Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, Lingming Zhang*  [[pdf](https://arxiv.org/abs/2305.01210)], 2023.5.2

1. **On Contrastive Learning of Semantic Similarity forCode to Code Search.**  Arxiv

    *Anthony Saieva, Saikat Chakraborty, Gail Kaiser*  [[pdf](https://arxiv.org/abs/2305.03843)], 2023.5.5

1. **Self-Edit: Fault-Aware Code Editor for Code Generation.** ACL 2023

    *Kechi Zhang, Zhuo Li, Jia Li, Ge Li, Zhi Jin*  [[pdf](https://arxiv.org/abs/2305.04087)], 2023.5.6

1. **ToolCoder: Teach Code Generation Models to use API search tools** Arxiv

   *Kechi Zhang, Huangzhao Zhang, Ge Li, Jia Li, Zhuo Li, Zhi Jin*  [[pdf](https://arxiv.org/abs/2305.04032)], 2023.5.6

1. **Code Execution with Pre-trained Language Models.** ACL 2023 Findings

    *Chenxiao Liu, Shuai Lu, Weizhu Chen, Daxin Jiang, Alexey Svyatkovskiy, Shengyu Fu, Neel Sundaresan, Nan Duan*  [[pdf](https://arxiv.org/abs/2305.05383)], 2023.5.8

1. **StarCoder: may the source be with you!** Arxiv

    *Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, Harm de Vries* [[pdf](https://arxiv.org/abs/2305.06161)], 2023.5.9

1. **SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs.** Arxiv

    *IokTong Lei, ZhiDong Deng*  [[pdf](https://arxiv.org/abs/2305.11461)], 2023.5.19

1. **Text-to-SQL Error Correction with Language Models of Code.** ACL 2023

     *Ziru Chen, Shijie Chen, Michael White, Raymond Mooney, Ali Payani, Jayanth Srinivasa, Yu Su, Huan Sun*  [[pdf](https://arxiv.org/abs/2305.13073)], 2023.5.22

1. **ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers.** Arxiv

     *Kexun Zhang, Danqing Wang, Jingtao Xia, William Yang Wang, Lei Li*  [[pdf](https://arxiv.org/abs/2305.14591)], 2023.5.24

1. **Tuning Models of Code with Compiler-Generated Reinforcement Learning Feedback.** Arxiv
   
     *Abhinav Jain, Chima Adiole, Swarat Chaudhuri, Thomas Reps, Chris Jermaine*  [[pdf](https://arxiv.org/abs/2305.18341)], 2023.5.25

1. **SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL.** Arxiv

    *Ruoxi Sun, Sercan O. Arik, Hootan Nakhost, Hanjun Dai, Rajarishi Sinha, Pengcheng Yin, Tomas Pfister*  [[pdf](https://arxiv.org/abs/2306.00739)], 2023.5.26

1. **Grammar Prompting for Domain-Specific Language Generation with Large Language Models.** Arxiv

     *Bailin Wang, Zi Wang, Xuezhi Wang, Yuan Cao, Rif A. Saurous, Yoon Kim*  [[pdf](https://arxiv.org/abs/2305.19234)], 2023.5.30

1. **SELFEVOLVE: A Code Evolution Framework via Large Language Models.** Arxiv

    *Shuyang Jiang, Yuhao Wang, Yu Wang* [[pdf](https://arxiv.org/abs/2306.02907)], 2023.6.5
   
1. **WizardCoder: Empowering Code Large Language Models with Evol-Instruct.** Arxiv

     *Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, Daxin Jiang*  [[pdf](https://arxiv.org/abs/2306.08568)], 2023.6.14

1. **Demystifying GPT Self-Repair for Code Generation.** Arxiv

     *Theo X. Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, Armando Solar-Lezama*  [[pdf](https://arxiv.org/abs/2306.09896)], 2023.6.16

1. **RepoFusion: Training Code Models to Understand Your Repository.** Arxiv

     *Disha Shrivastava, Denis Kocetkov, Harm de Vries, Dzmitry Bahdanau, Torsten Scholak*  [[pdf](https://arxiv.org/abs/2306.10998)], 2023.6.19

1. **Guiding Language Models of Code with Global Context using Monitors.** Arxiv

     *Lakshya A Agrawal, Aditya Kanade, Navin Goyal, Shuvendu K. Lahiri, Sriram K. Rajamani*  [[pdf](https://arxiv.org/abs//2306.10763)], 2023.6.19

1. **Textbooks Are All You Need.** Arxiv

     *Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, Yuanzhi Li*  [[pdf](https://arxiv.org/abs/2306.11644)], 2023.6.20

1. **Language models are weak learners.** Arxiv

     *Hariharan Manikandan, Yiding Jiang, J Zico Kolter*  [[pdf](https://arxiv.org/abs/2306.14101)], 2023.6.25

1. **LongCoder: A Long-Range Pre-trained Language Model for Code Completion.** Arxiv

     *Daya Guo, Canwen Xu, Nan Duan, Jian Yin, Julian McAuley*  [[pdf](https://arxiv.org/abs/2306.14893)], 2023.6.26

1. **InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback.** Arxiv

     *John Yang, Akshara Prabhakar, Karthik Narasimhan, Shunyu Yao*  [[pdf](https://arxiv.org/abs/2306.14898)], 2023.6.26

1. **A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis** Arxiv

     *Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, Aleksandra Faust*  [[pdf](https://arxiv.org/abs/2307.12856)], 2023.7.24

1. **Predicting Code Coverage without Execution** Arxiv

    *Michele Tufano, Shubham Chandel, Anisha Agarwal, Neel Sundaresan, Colin Clement*  [[pdf](https://arxiv.org/abs/2307.13383)], 2023.7.25

1. **ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis** Arxiv

   *Kensen Shi, Joey Hong, Manzil Zaheer, Pengcheng Yin, Charles Sutton* [[pdf](https://arxiv.org/abs/2307.13883)], 2023.7.26
   
1. **Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models**  Arxiv

   *Cheng-Yu Hsieh, Si-An Chen, Chun-Liang Li, Yasuhisa Fujii, Alexander Ratner, Chen-Yu Lee, Ranjay Krishna, Tomas Pfister*  [[pdf](https://arxiv.org/abs/2308.00675)], 2023.8.1

1. **Symbolic Planning and Code Generation for Grounded Dialogue** EMNLP 2023

   *Justin T. Chiu, Wenting Zhao, Derek Chen, Saujas Vaduguru, Alexander M. Rush, Daniel Fried* [[pdf](https://arxiv.org/abs/2310.17140)], 2023.10.26

1. **Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation** EMNLP 2023

   *Hailin Chen, Amrita Saha, Steven Hoi, Shafiq Joty* [[pdf](https://arxiv.org/abs/2310.18628)], 2023.10.28

1. **LILO: LEARNING INTERPRETABLE LIBRARIES BY COMPRESSING AND DOCUMENTING CODE** Arxiv

    *Gabriel Grand, Lionel Wong, Matthew Bowers, Theo X. Olausson, Muxin Liu, Joshua B. Tenenbaum, Jacob Andreas* [[pdf](https://arxiv.org/abs/2310.19791)], 2023.10.30

1. **InstructCoder: Empowering Language Models for Code Editing** Arxiv

    *Qisheng Hu, Kaixin Li, Xu Zhao, Yuxi Xie, Tiedong Liu, Hui Chen, Qizhe Xie, Junxian He* [[pdf](https://arxiv.org/abs/2310.20329)], 2023.10.31

1. **Data Augmentation for Code Translation with Comparable Corpora and Multiple References**, EMNLP 2023 Findings

    *Yiqing Xie, Atharva Naik, Daniel Fried, Carolyn Rose* [[pdf](https://arxiv.org/abs/2311.00317)], 2023.11.1

1. **Safurai-Csharp: Harnessing Synthetic Data to improve language-specific Code LLM**

   *Davide Cifarelli, Leonardo Boiardi, Alessandro Puppo, Leon Jovanovic* [[pdf](https://arxiv.org/abs/2311.03243)], 2023.11.6

1. **Retrieval-Augmented Code Generation for Universal Information Extraction**
    
    *Yucan Guo, Zixuan Li, Xiaolong Jin, Yantao Liu, Yutao Zeng, Wenxuan Liu, Xiang Li, Pan Yang, Long Bai, Jiafeng Guo, Xueqi Cheng*  [[pdf](https://arxiv.org/abs/2311.02962)], 2023.11.6

1. **Past as a Guide: Leveraging Retrospective Learning for Python Code Completion**, Neurips 2023 Workshop

   *Seunggyoon Shin, Seunggyu Chang, Sungjoon Choi*  [[pdf](https://arxiv.org/abs/2311.07635)], 2023.11.13

1. **Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback**

   *Seungjun Moon, Yongho Song, Hyungjoo Chae, Dongjin Kang, Taeyoon Kwon, Kai Tzu-iunn Ong, Seung-won Hwang, Jinyoung Yeo*  [[pdf](https://arxiv.org/abs/2311.07215)], 2023.11.13

1. **Explain-then-Translate: An Analysis on Improving Program Translation with Self-generated Explanations**

   *Zilu Tang, Mayank Agarwal, Alex Shypula, Bailin Wang, Derry Wijaya, Jie Chen, Yoon Kim*, 2023.11.13

1. **CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation**

   *https://arxiv.org/abs/2311.08588*  [[pdf](https://arxiv.org/abs/2311.08588)], 2023.11.14

1. **ML-Bench: Large Language Models Leverage Open-source Libraries for Machine Learning Tasks**

   *Yuliang Liu, Xiangru Tang, Zefan Cai, Junjie Lu, Yichi Zhang, Yanjun Shao, Zexuan Deng, Helan Hu, Zengxian Yang, Kaikai An, Ruijun Huang, Shuzheng Si, Sheng Chen, Haozhe Zhao, Zhengliang Li, Liang Chen, Yiming Zong, Yan Wang, Tianyu Liu, Zhiwei Jiang, Baobao Chang, Yujia Qin, Wangchunshu Zhou, Yilun Zhao, Arman Cohan, Mark Gerstein*  [[pdf](https://arxiv.org/abs/2311.09835)], 2023.11.16

1. **GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization in Programming Language Understanding**

   *Andor Diera, Abdelhalim Dahou, Lukas Galke, Fabian Karl, Florian Sihler, Ansgar Scherp*  [[pdf](https://arxiv.org/abs/2311.09707)], 2023.11.16

1. **Evaluating In-Context Learning of Libraries for Code Generation**

   *Arkil Patel, Siva Reddy, Dzmitry Bahdanau, Pradeep Dasigi*  [[pdf](https://arxiv.org/abs/2311.09635)], 2023.11.16

1. **Function-constrained Program Synthesis**, 2023 NeurIPS R0-Fomo Workshop

   *Patrick Hajali, Ignas Budvytis*  [[pdf](https://arxiv.org/abs/2311.15500)], 2023.11.27

1. **Applications of Large Language Models in Data Processing: Innovative Approaches to Segmenting and Renewing Information**

   *Yu-Chen Lin, Akhilesh Kumar, Wen-Liang Zhang, Norman Chang, Muhammad Zakir, Rucha Apte, Chao Wang, Jyh-Shing Roger Jang*  [[pdf](https://arxiv.org/abs/2311.16267)], 2023.11.27

1. **Self-Infilling Code Generation**

   *Lin Zheng, Jianbo Yuan, Zhi Zhang, Hongxia Yang, Lingpeng Kong*  [[pdf](https://arxiv.org/abs/2311.17972)], 2023.11.29











   





    

